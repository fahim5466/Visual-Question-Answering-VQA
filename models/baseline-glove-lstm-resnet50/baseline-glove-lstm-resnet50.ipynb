{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vulnerable-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical, plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, LSTM\n",
    "from tensorflow.keras import callbacks\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "import pydot\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dried-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oriented-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overall-purchase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_path</th>\n",
       "      <th>ques</th>\n",
       "      <th>answ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_train2014_000000474075.jpg</td>\n",
       "      <td>What sport is on the TV?</td>\n",
       "      <td>bowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_train2014_000000407548.jpg</td>\n",
       "      <td>Is she playing with a ball?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_train2014_000000060180.jpg</td>\n",
       "      <td>What is the green vegetable?</td>\n",
       "      <td>broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_train2014_000000064141.jpg</td>\n",
       "      <td>What is the green stuff on the food?</td>\n",
       "      <td>basil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_train2014_000000403506.jpg</td>\n",
       "      <td>What color is his shirt?</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388149</th>\n",
       "      <td>COCO_train2014_000000247789.jpg</td>\n",
       "      <td>Is there spinach on the pizza?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388150</th>\n",
       "      <td>COCO_train2014_000000151615.jpg</td>\n",
       "      <td>Are there clouds visible?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388151</th>\n",
       "      <td>COCO_train2014_000000363939.jpg</td>\n",
       "      <td>How many trains can be seen?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388152</th>\n",
       "      <td>COCO_train2014_000000361275.jpg</td>\n",
       "      <td>What material is the bench made of?</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388153</th>\n",
       "      <td>COCO_train2014_000000519319.jpg</td>\n",
       "      <td>Is the bus moving?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388154 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                im_path                                  ques  \\\n",
       "0       COCO_train2014_000000474075.jpg              What sport is on the TV?   \n",
       "1       COCO_train2014_000000407548.jpg           Is she playing with a ball?   \n",
       "2       COCO_train2014_000000060180.jpg          What is the green vegetable?   \n",
       "3       COCO_train2014_000000064141.jpg  What is the green stuff on the food?   \n",
       "4       COCO_train2014_000000403506.jpg              What color is his shirt?   \n",
       "...                                 ...                                   ...   \n",
       "388149  COCO_train2014_000000247789.jpg        Is there spinach on the pizza?   \n",
       "388150  COCO_train2014_000000151615.jpg             Are there clouds visible?   \n",
       "388151  COCO_train2014_000000363939.jpg          How many trains can be seen?   \n",
       "388152  COCO_train2014_000000361275.jpg   What material is the bench made of?   \n",
       "388153  COCO_train2014_000000519319.jpg                    Is the bus moving?   \n",
       "\n",
       "            answ  \n",
       "0        bowling  \n",
       "1             no  \n",
       "2       broccoli  \n",
       "3          basil  \n",
       "4          black  \n",
       "...          ...  \n",
       "388149       yes  \n",
       "388150       yes  \n",
       "388151         1  \n",
       "388152      wood  \n",
       "388153        no  \n",
       "\n",
       "[388154 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../datasets/vqa-v1/train_data.csv')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documentary-richardson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_path</th>\n",
       "      <th>ques</th>\n",
       "      <th>answ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_val2014_000000069923.jpg</td>\n",
       "      <td>What are they standing on?</td>\n",
       "      <td>sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_val2014_000000387696.jpg</td>\n",
       "      <td>How many people are there?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_val2014_000000523871.jpg</td>\n",
       "      <td>Where is the wicker chair?</td>\n",
       "      <td>living room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_val2014_000000223198.jpg</td>\n",
       "      <td>What color is the subject's tie?</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_val2014_000000341246.jpg</td>\n",
       "      <td>Are these normal-sized donuts?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186474</th>\n",
       "      <td>COCO_val2014_000000006789.jpg</td>\n",
       "      <td>Are the cars moving?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186475</th>\n",
       "      <td>COCO_val2014_000000547300.jpg</td>\n",
       "      <td>Is the ball green?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186476</th>\n",
       "      <td>COCO_val2014_000000154520.jpg</td>\n",
       "      <td>Are there buildings in the background?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186477</th>\n",
       "      <td>COCO_val2014_000000388903.jpg</td>\n",
       "      <td>What company does the man in the background wo...</td>\n",
       "      <td>fedex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186478</th>\n",
       "      <td>COCO_val2014_000000367195.jpg</td>\n",
       "      <td>What is the dog laying on?</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186479 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              im_path  \\\n",
       "0       COCO_val2014_000000069923.jpg   \n",
       "1       COCO_val2014_000000387696.jpg   \n",
       "2       COCO_val2014_000000523871.jpg   \n",
       "3       COCO_val2014_000000223198.jpg   \n",
       "4       COCO_val2014_000000341246.jpg   \n",
       "...                               ...   \n",
       "186474  COCO_val2014_000000006789.jpg   \n",
       "186475  COCO_val2014_000000547300.jpg   \n",
       "186476  COCO_val2014_000000154520.jpg   \n",
       "186477  COCO_val2014_000000388903.jpg   \n",
       "186478  COCO_val2014_000000367195.jpg   \n",
       "\n",
       "                                                     ques         answ  \n",
       "0                              What are they standing on?         sand  \n",
       "1                              How many people are there?            3  \n",
       "2                              Where is the wicker chair?  living room  \n",
       "3                        What color is the subject's tie?          red  \n",
       "4                          Are these normal-sized donuts?          yes  \n",
       "...                                                   ...          ...  \n",
       "186474                               Are the cars moving?          yes  \n",
       "186475                                 Is the ball green?           no  \n",
       "186476             Are there buildings in the background?           no  \n",
       "186477  What company does the man in the background wo...        fedex  \n",
       "186478                         What is the dog laying on?       carpet  \n",
       "\n",
       "[186479 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv('../datasets/vqa-v1/val_data.csv')\n",
    "\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extreme-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_path</th>\n",
       "      <th>ques</th>\n",
       "      <th>ques_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_test2015_000000361284.jpg</td>\n",
       "      <td>What color is her surfboard?</td>\n",
       "      <td>361284002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_test2015_000000580877.jpg</td>\n",
       "      <td>What is the woman standing on?</td>\n",
       "      <td>580877008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COCO_test2015_000000097764.jpg</td>\n",
       "      <td>How many tennis balls are there?</td>\n",
       "      <td>97764005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCO_test2015_000000112725.jpg</td>\n",
       "      <td>Is there cereal in the bowl?</td>\n",
       "      <td>112725009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCO_test2015_000000453690.jpg</td>\n",
       "      <td>What color is the men's sunglasses?</td>\n",
       "      <td>453690003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447788</th>\n",
       "      <td>COCO_test2015_000000000565.jpg</td>\n",
       "      <td>What is the cat laying on?</td>\n",
       "      <td>565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447789</th>\n",
       "      <td>COCO_test2015_000000129714.jpg</td>\n",
       "      <td>How many beer bottles are on the table?</td>\n",
       "      <td>129714005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447790</th>\n",
       "      <td>COCO_test2015_000000165846.jpg</td>\n",
       "      <td>What sports equipment is he holding?</td>\n",
       "      <td>165846001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447791</th>\n",
       "      <td>COCO_test2015_000000272125.jpg</td>\n",
       "      <td>Why is the cat dressed up?</td>\n",
       "      <td>272125002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447792</th>\n",
       "      <td>COCO_test2015_000000366374.jpg</td>\n",
       "      <td>Are the elephants going upstairs?</td>\n",
       "      <td>366374001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447793 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               im_path  \\\n",
       "0       COCO_test2015_000000361284.jpg   \n",
       "1       COCO_test2015_000000580877.jpg   \n",
       "2       COCO_test2015_000000097764.jpg   \n",
       "3       COCO_test2015_000000112725.jpg   \n",
       "4       COCO_test2015_000000453690.jpg   \n",
       "...                                ...   \n",
       "447788  COCO_test2015_000000000565.jpg   \n",
       "447789  COCO_test2015_000000129714.jpg   \n",
       "447790  COCO_test2015_000000165846.jpg   \n",
       "447791  COCO_test2015_000000272125.jpg   \n",
       "447792  COCO_test2015_000000366374.jpg   \n",
       "\n",
       "                                           ques    ques_id  \n",
       "0                  What color is her surfboard?  361284002  \n",
       "1                What is the woman standing on?  580877008  \n",
       "2              How many tennis balls are there?   97764005  \n",
       "3                  Is there cereal in the bowl?  112725009  \n",
       "4           What color is the men's sunglasses?  453690003  \n",
       "...                                         ...        ...  \n",
       "447788               What is the cat laying on?     565000  \n",
       "447789  How many beer bottles are on the table?  129714005  \n",
       "447790     What sports equipment is he holding?  165846001  \n",
       "447791               Why is the cat dressed up?  272125002  \n",
       "447792        Are the elephants going upstairs?  366374001  \n",
       "\n",
       "[447793 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../datasets/vqa-v1/test_data.csv')\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reserved-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_embeddings = dict()\n",
    "directory = '../datasets/vqa-v1/images/train_image_features/'\n",
    "files = os.listdir(directory)\n",
    "for i, file in enumerate(files):\n",
    "    #print('processed',i+1,'features',end='\\r')\n",
    "    feature = np.load(directory+file)['arr_0']\n",
    "    name = file[:-4]\n",
    "    train_image_embeddings[name] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attractive-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_embeddings = dict()\n",
    "directory = '../datasets/vqa-v1/images/val_image_features/'\n",
    "files = os.listdir(directory)\n",
    "for i, file in enumerate(files):\n",
    "    #print('processed',i+1,'features',end='\\r')\n",
    "    feature = np.load(directory+file)['arr_0']\n",
    "    name = file[:-4]\n",
    "    val_image_embeddings[name] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "encouraging-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "[ 0.0033901 -0.34614    0.28144    0.48382    0.59469    0.012965\n",
      "  0.53982    0.48233    0.21463   -1.0249    -0.34788   -0.79001\n",
      " -0.15084    0.61374    0.042811   0.19323    0.25462    0.32528\n",
      "  0.05698    0.063253  -0.49439    0.47337   -0.16761    0.045594\n",
      "  0.30451   -0.35416   -0.34583   -0.20118    0.25511    0.091111\n",
      "  0.014651  -0.017541  -0.23854    0.48215   -0.9145    -0.36235\n",
      "  0.34736    0.028639  -0.027065  -0.036481  -0.067391  -0.23452\n",
      " -0.13772    0.33951    0.13415   -0.1342     0.47856   -0.1842\n",
      "  0.10705   -0.45834  ]\n"
     ]
    }
   ],
   "source": [
    "#question feature extraction\n",
    "#glove embeddings\n",
    "\n",
    "glove_embeddings = dict()\n",
    "f = open('../datasets/pre-trained/glove/glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  coefs = np.asarray(values[1:], dtype='float64')\n",
    "  glove_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(len(glove_embeddings))\n",
    "print(glove_embeddings['king'][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "realistic-motivation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stuffed animals', '20', 'statue', 'clock', 'food', 'saddle', 'beer', '30', 'surf', 'plants', 'pole', 'waves', 'road', 'ski', '8', 'cabinet', 'heart', 'gold', 'women', 'sitting', 'cake', 'trees', 'not possible', 'wii controller', 'warm', 'teddy bears', 'tulips', '21', 'blue and white', 'string', '1', 'pelican', 'dog', 'yes', 'window', 'cone', 'fireplace', 'vest', 'sun', 'female', 'brick', 'pillow', 'waiting', 'ski lift', 'overcast', 'fall', 'strawberry', 'dining room', 'red and blue', 'taking picture', 'soccer', 'business', 'playing game', 'p', 'shallow', 'basil', 'bun', 'washington', 'star', '3', 'typing', 'skis', 'birds', 'bottle', 'gray and white', 'tattoo', '4', 'mountains', 'italy', 'steel', 'cows', 'sink', 'fake', 'new york', 'surfing', 'happy', 'zoo', 'noon', 'plain', 'w', 'away', 'football', 'orange juice', 'tree', 'turkey', 'boots', 'apples', 'water', 'no', 'train station', 'in water', 'suit', 'african', 'lufthansa', 'foil', 'bottles', 'roman', 'chocolate', 'dusk', 'polar']\n"
     ]
    }
   ],
   "source": [
    "#answer feature extraction\n",
    "answers = list(pd.unique(train_data['answ']))\n",
    "random.shuffle(answers)\n",
    "print(answers[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "integrated-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datagen(Sequence):\n",
    "    \n",
    "    def __init__(self, dataframe, split, batch_size, predict_mode=False):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.predict_mode = predict_mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.dataframe) / self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, ind):\n",
    "        \n",
    "        #print('Starting batch',ind)\n",
    "        \n",
    "        partial_dataframe = self.dataframe[ind * self.batch_size : (ind + 1) * self.batch_size]\n",
    "        \n",
    "        img_path = list(partial_dataframe['im_path'])\n",
    "        ques = list(partial_dataframe['ques'])\n",
    "        if not self.predict_mode:\n",
    "            ans = list(partial_dataframe['answ'])\n",
    "        \n",
    "        image_features = self.get_img_feature(img_path)\n",
    "        question_features = self.get_ques_feature(ques)\n",
    "\n",
    "        if not self.predict_mode:\n",
    "            answer_features = self.get_ans_feature(ans)\n",
    "        \n",
    "        x = (image_features, question_features)\n",
    "        if not self.predict_mode:\n",
    "            y = answer_features\n",
    "        \n",
    "        #print('Finished batch',ind+1)\n",
    "        \n",
    "        if self.predict_mode:\n",
    "            return x, \n",
    "        else:\n",
    "            return x, y\n",
    "    \n",
    "    def get_img_feature(self, img_path):\n",
    "        \n",
    "        #print('getting image feature')\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            image_embeddings = train_image_embeddings\n",
    "        else:\n",
    "            image_embeddings = val_image_embeddings\n",
    "        \n",
    "        r = np.ndarray((len(img_path), 2048), dtype='float32')\n",
    "        \n",
    "        for i, path in enumerate(img_path):\n",
    "            img = image_embeddings[path[:-4]]\n",
    "            r[i] = img\n",
    "            \n",
    "        return r\n",
    "    \n",
    "    def get_ques_feature(self, ques):\n",
    "        \n",
    "        #print('getting question feature')\n",
    "        \n",
    "        r = np.zeros((len(ques), 15, 300), dtype='float32')\n",
    "        default = np.zeros((300), dtype='float32')\n",
    "        \n",
    "        for i, q in enumerate(ques):\n",
    "            \n",
    "            table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "            q = q.translate(table).lower()\n",
    "            words = q.split()[:15]\n",
    "            e = [glove_embeddings.get(w, default) for w in words]\n",
    "            r[i,:len(e)] = e\n",
    "            \n",
    "        return r\n",
    "    \n",
    "    def get_ans_feature(self, ans):\n",
    "        \n",
    "        #print('getting answer feature')\n",
    "        \n",
    "        r = np.zeros((len(ans), 1000), dtype='float32')\n",
    "        \n",
    "        for i, a in enumerate(ans):\n",
    "            ind = answers.index(a)\n",
    "            r[i][ind] = 1.0\n",
    "            \n",
    "        return r\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.dataframe = self.dataframe.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "neither-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmask = train_data[\\'ques\\'].str.startswith(\"What animal\")\\n\\ntrain_data_whatanimal = train_data[mask]\\nprint(len(train_data_whatanimal))\\n\\ntest_data_whatanimal = train_data_whatanimal.loc[[768]]\\n\\ntrain_data_whatanimal = train_data_whatanimal.drop([768])\\nprint(len(train_data_whatanimal))\\n\\n#train_data_whatanimal.loc[[768]]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mask = train_data['ques'].str.startswith(\"What animal\")\n",
    "\n",
    "train_data_whatanimal = train_data[mask]\n",
    "print(len(train_data_whatanimal))\n",
    "\n",
    "test_data_whatanimal = train_data_whatanimal.loc[[768]]\n",
    "\n",
    "train_data_whatanimal = train_data_whatanimal.drop([768])\n",
    "print(len(train_data_whatanimal))\n",
    "\n",
    "#train_data_whatanimal.loc[[768]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparable-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_datagen = datagen(train_data, 'train', batch_size=batch_size)\n",
    "'''\n",
    "for x in train_datagen:\n",
    "    \n",
    "    print('image features')\n",
    "    print(x[0][0][0].shape)\n",
    "    print(x[0][0][0])\n",
    "        \n",
    "    print('question features')\n",
    "    print(x[0][1][0].shape)\n",
    "    print(x[0][1][0])\n",
    "        \n",
    "    print('answer features')\n",
    "    print(x[1][0].shape)\n",
    "    print(x[1][0])\n",
    "    break\n",
    "'''\n",
    "\n",
    "val_datagen = datagen(val_data, 'val', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "czech-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(2048), dtype='float32', name='image_input')\n",
    "\n",
    "input2 = Input(shape=(15, 300), dtype='float32', name='question_input')\n",
    "#flattened = Flatten(dtype='float32', name='flatten_question')(input2)\n",
    "\n",
    "#img_encode = Dense(512, activation='relu', dtype='float32', name='img_encode')(input1)\n",
    "ques_encode = LSTM(512, name='ques_encode')(input2)\n",
    "\n",
    "concatenated = Concatenate(dtype='float32', name='concatenate')([input1, ques_encode])\n",
    "\n",
    "fc1 = Dense(512, activation='relu', dtype='float32', name='fc1')(concatenated)\n",
    "#fc2 = Dense(256, activation='relu', dtype='float32', name='fc2')(fc1)\n",
    "output = Dense(1000, activation='softmax', dtype='float32', name='classification')(fc1)\n",
    "\n",
    "model = Model(inputs=[input1,input2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "careful-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_input (InputLayer)     [(None, 15, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_input (InputLayer)        [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ques_encode (LSTM)              (None, 512)          1665024     question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2560)         0           image_input[0][0]                \n",
      "                                                                 ques_encode[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 512)          1311232     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 1000)         513000      fc1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 3,489,256\n",
      "Trainable params: 3,489,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "phantom-lemon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAHBCAYAAADq7PU3AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de3Sb9X3H8c+D48AKNIGVZCcZ4U52xiXbOF0TGsiSEgoJMlDiENu5LBRSuUAPGTktF3llIxuHTd6l0CbYXAbBlkmgUCsJaQ8xI1zswdicclJwOihKoAd5G0jd6Aq5/PZH+qiSrMsj2dZj/fx+naOT6HkePb/vc9Hvo+ci2THGGAEAYJGj/C4AAICRRrgBAKxDuAEArEO4AQCsMyF7wAcffKC1a9fq0KFDftQDjGsrVqxQIBDwuwyg6g05cuvp6VFXV5cftQDj2pYtW3jvASNkyJGba/PmzZWsAxj3mpqa/C4BsAbX3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWGRfh1tLSopaWlnFfAwCMF9aFWzKZlOM4fpcx5pSzXhzHyfnwQ3b9Y6k2AGNP3j9WWq127do1ZNjdd9/tQyVjq4Zc66UYY4ySyaQmT54sSUokEpo0adJIl+ZJdv3GGA0ODmrq1KmS/K0NwNhj1ZFbMplUe3u732WMOcNZL+mB4Vd45Kt/ypQpqf8TbADSjWi4dXV1qa6uTnV1derr61M0Gk2dKsp16ijf6aTBwUG1trbKcRzV1dWpp6cnY7w7rr29XYODg6nXh8NhRaPRjHkPDg6m6kqXTCbV1dWVms6dV3oN6a9zl6Wurk779u0rab1kz8vLvAcHBxWNRlPTtLe3y3EcNTc3a+/evQXXYfawXOtFKv864FipvxRuQLqvb2lpydjP3Edra2vqNenj0pcr176ZvrzJZFLNzc1cYwX8ZLJ0dHSYHIOLCoVCJhAImHg8bowxZufOnUZSal7xeDzjuTHGxGKxIcPi8bgJBAImEolkzKe/v98YY0w4HDaxWMwYY0wikTChUCjj9dnzCwQCQ4a5w9va2jLaDAQCJpFIDHldb29vRr3BYLCkdZNdg5d5u+PTp0kkEiYYDBpJZmBgoKT1mmsdhEIhEwqFitZfaJ36WX+h4dncduPx+JBae3t7827X9H260L6ZvU76+/tL3k8aGxtNY2NjSa8BkNuIhFt2AKVm7qGDyh4WiURyTuN2wm4H5XI7x1LacOtNn4/bwbkdl9d5eVXOusg1TX9/v5FkwuHwsOdVbu1jqX6vyxUKhTLCJvt14XDYSEp9cHJrTd8fvOybklIfkEpFuAEjZ0TCzf1UPGTmZXTo6Z+Asx/pbUUikZydiJc2ctWbSCSMJBMIBEqal1cjFW4jPa9yah9L9Ze6XLFYLBVk6a9zQ9c9mjcm8yyBMcX3zeGsY2MIN2AkjUi4VbITHhgYyOhk0o8AhttGOfV6RbiNTv2lLFdbW5sJBAJmYGAg5+vcDz2JRCJ1CrWUtgg3YOwYs3dLpt90kO7ss89Wd3e3+vv7FQwGtW7duoybALwIBAKSlHEDiSsYDJZerA+qpc58KlV/c3OzpCM3O61Zs0b333+/zj777II1Pfvss9q1a5dWrVqVc7p8+yaAsWNEwi0cDkuSdu/ePex5tbW1SZI2bdqkZDIp6Td3qElH7pZLJpOaNWuWNmzYoP7+fq1bt66kNhobGyVJ77zzTmqY21Z9ff2wl2E0uR3rokWLfK6kPJWsv6+vT/PmzZMkNTQ0SJJmzJiRd/pZs2YpGAyqoaFB7e3tmj17dsb4YvsmgDEk+1CunNOS7mmeQCCQukbR3d2d91qXe6ecexOH9Js71dLvnkt/uPOVjlzAd5+711Bc7inLeDxuwuFwxvzcG0gSiUTq7kh3WCQSyTgNlf4699qee10ufV5eZNfgdd7uc/emBvfu0PTrgl7Xa/Z6Mcbb3ZLpdbm1jpX6c91p6XLn4d7k5L4+FotlnJbM3o7u69KvvbkK7ZuFavGK05LAyBmxrwK4tz67HUN6Z+eKxWKpTqa7u9sYY1K3Vqd3MrFYLHWLfzAYzLion97BKcc1N/fGgFAolLMzcsXjcdPW1pbRAaffoJLrdfnmVUyuDtHLvN3/p99q7q7bdF7Wa/Z6MaZ4uBWr28/6vdbmtpX9evfuyfR9y+Vel8sl376Z3mZ2eHtFuAEjxzHGGKXp7OxUU1OTsgaXxf2y7UjMazyq9vVXjfUnk0nddttt2rBhQ8XbbmpqkiR1dHRUvG3ANmP2hhLAD5s3bx7z110BFDdq4Zb9U1YoTbWvv2qqv6WlJeNnthYsWOB3SQCGadT+KoD7a+3u/6vp1JRXXn/jsJxlr/b1V031u3dQtrW16YYbbvC5GgAjYdTCbSx3ZiNlNJex2tdfNdV/ww03EGqAZbjmBgCwDuEGALAO4QYAsA7hBgCwDuEGALAO4QYAsA7hBgCwDuEGALAO4QYAsA7hBgCwDuEGALAO4QYAsA7hBgCwTt6/CrB06dJK1gGMe1u2bFFjY6PfZQBWGHLktmDBAi1btsyPWjACdu3aNeb/OChyq6+v570HjBDHVNMf3kJRjuOoo6ODIwAA4xrX3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANZxjDHG7yJQnqeeekq33367pk2blhr28ssva+bMmfrc5z4nSUokEpo7d67uv/9+v8oEgIoj3KpYS0uL1q9f72laNjOA8YTTklWsoaGh6DS1tbW66667Rr8YABhDOHKrcueee6727NlTcJq33npLM2fOrFBFAOA/jtyq3PLly1VbW5tznOM4Ov/88wk2AOMO4VblGhoadPDgwZzjampqtGrVqgpXBAD+47SkBWbPnq3XXntNhw8fzhjuOI7279+v6dOn+1QZAPiDIzcLrFq1So7jZAw76qijdOGFFxJsAMYlws0CS5YsGTLMcRytXLnSh2oAwH+EmwVOOukkzZ8/XzU1NalhjuPkDD0AGA8IN0usXLky9UXtmpoaLVy4UCeeeKLPVQGAPwg3S1x11VWprwQYY7R8+XKfKwIA/xBuljj++OO1ePFiSdLEiRN15ZVX+lwRAPhnQqUa6u3t1XvvvVep5sal008/PfXv9u3bfa7GbjU1Naqrq9OECaPzFjp48KC6u7t16NChUZk/YJPZs2fr5JNPzhxoKkQSDx5WPZ5++ulRe788/fTTvi8fDx7V8li9evWQ91DFjtwkqaOjQ42NjZVsEhgVjuPol7/85ajN35234TcWgIKampr0ySefDBnONTcAgHUINwCAdQg3AIB1CDcAgHUINwCAdQg3AIB1CDcAgHUINwCAdQg3AIB1CDcAgHUINwCAdQg3AIB1CDcAgHUINwCAdQi3cWZwcFBdXV2qq6vzuxSMsJaWFrW0tPhdxoiycZlQGYTbOPPtb39bDQ0NikajIzZPx3FyPgrp6+tTc3OzHMdRc3Ozenp6lEwmM16Xb75eH319fQXbL6VejE/Z+6QX5bwfRovX95SNCLdxZsOGDSM+T2OM4vF46nkikSj4Rzb7+vo0Z84czZs3T8YYbdiwQb/927+tFStWDJk2EonIGJN6pLfpPiKRSGpYLBZLTfPoo4/mrSF9XDwet+KPgt599926++67/S5jRPm9TLt27Sr5NcYYJRKJ1PNi74fRlF1/qe/Vaka4YURMmTIl9f9JkyYVnNYNlmXLlqWGzZo1K2cnlj5NPpdffnnq/zNmzJAkhcNhbdy4Ufv27Rsy/b59+3TmmWfmrB1wJZNJtbe3l/Xa9PdAsffDaMlXfynv1Wo25sPNvT5UV1envr4+RaPR1GF0rsPqfIfag4ODam1tleM4qqurU09PT8Z4d1x7e7sGBwfLPlTP1072tS53Oerq6oZ0wMlkUl1dXanlyLWD5ppmcHCw4HR1dXXau3dvSXVLI3/d4/3335ck7d69O2P4rFmzMp6nH4UVMmnSpCHTXnLJJZKkV155Zcj0r7zySmq8LbL3r3z7W3Nzc2p/c/eL9GHSbzpFd99qaWkZsm/19PSorq5OjuOotbU1575X7D03UsuU/h4aHBxUNBpNTeMuR3Nzc8a+76XvCIfDqdP36cPLfT+MlfpLkW9fcLer+2htbU29Jn1c+nLl6xfd5U0mk2pubh65vsZUiCTT0dFR0mtCoZAJBAImHo8bY4zZuXOnkWTcsuPxeMZzY4yJxWJDhsXjcRMIBEwkEsmYT39/vzHGmHA4bGKxmDHGmEQiYUKhkCln1RRqJxAIpOrq7e3NqDUYDGbMJxAImFAolHoeDAYznrvTtLW1ZbQbCARMIpEYMl0wGEwNj0QiJa+fUCg0pP1csuebT39/f2ratra2ITUPtw13fDAYzDmtu7691puvjVL351J0dHSUVFv6/pX93N2Ovb29qf2t0D7orrd4PJ5zfHd3d8Z+nL5Ppb83C+1Tw12mfPWn1+FOk0gkUss0MDCQqs9L35FrHyn3/TBW6i80PFuhfSF9f8qW3m+X0i/29/fnnF8hjY2NprGxcegyljSXYSi1M8j3ZvCy8bKHuW++7GncHdTdeC53xymVl3a81ppeT29vrwkEAqnn7rrJnkZSagcy5jedkPuGMObIG6XU9eNVKWExMDCQeuO4dXsJuVLCzV1PbidhzJFg3blzZ8n15mpjLIWbMeW9N3INC4VCGR2M1/mGw+HU89Hap7zUn2sa9wNVeo3lzqvc2sdS/V6Xq9i+EA6HjaTUwYFba3o/5LVfLOVDbrqqC7d8n7rL2dnTPx1kP9Lb8trB5lOsnVJqLSTXunFDKz0Eva7DYnV7Vc5rent7M0Kuu7t72G1k7x/pb870zpVwyz/MmCNHAm7nlT4+135VqX1qJDv0agq3ka6/1OXKty+4oeueRTIm80yYMeX1i6WounCr5A46MDCQsQHSPx2Volg7I/VmGs66KbdNL4YzH/fotFjAlRpu7qfGWCxm4vF4xidKwi3/sLa2NhMIBMzAwEDeDs1dl16PKspBuI1O/aUsV6F9wZjffNhJJBKpU6iltEW45RleygZOPz2Xi3u+t9yAK9aOl1rdDr7QtQl3mvTTku68Cp1CyDfc6/oppthOmn5dIdcRcq5rBqW24U6TPc9IJGIikUjGJ0rCLfew9A8E+V7T3d2d+iSffj0le54jvU8Nt0Mv9v4Y6+E2UvV7fa962RfSP+x0d3dnXAZIf00p/WIp8oXbmL1bMhwOSxp6R1052traJEmbNm1SMpmU9Ju7d6QjdxIlk0nNmjVLGzZsUH9/v9atWzfi7XgRCAQkSRs3bkzNY9++fWpubk5N09jYKEl65513UsPcaevr64fUU2wdjkTdxfT19WnevHmp56+//vqQadzb+N11MBJmzJihUCikhoYGvf/++6k2kF9DQ4Mk5V1X0WhUF198sW699VYZY9Td3T3kKxuV2KdK4d5puGjRIl/aH65K1p/+Xi22L0hH7nIOBoNqaGhQe3u7Zs+enTHet32h7LgskUr8pOseAgcCgdSnBvcGifSys+8icm+sUNqnnPQ7i9If6Z9GQqFQ6rl7frlUhdpJH+cetaTf3JF9Z1H664PB4JCbQty7I93XRSKRIacD3KOW9HWYfsep1/Xj5e6wXHdvudxt4h6NutPt3LkzY124nxLzHbWmt5F91Jo9Tfp495Nl+ny9zKuQUvfnUpV65Ja9PLn2t1zLnGuYu//FYrGMU1Hu+Fz7irs/5Zpvrn1qpJYp13vIfe4eTbp3QKdfjzbGW9+RfpbE7RO8vB/S68q1/v2sv5T3arF9Ift16dfeXF77xXJV3WlJYzJPE7q3jGeviFgsNuRajXuaJH0DxGKx1C3+wWBwyOkpd+NL5V9zK9RO9obNN8yYIzuDO49QKJTzcD4ej5u2traMN0K+U33uOnQ7n1LXT7E3c77OLvvh1ucu68DAQMYy5FvWQm0Um8aV63ROoXkVM9bCrdi6zzVNvmHuh4FQKJTaF9P3iexbuLMDzlVon6rEMqXXmesrJ176jux1YczIvR/8qL/U92qxfSGde10uFy/9YnZ4e5Uv3JxfNzDqHMdRR0dH6pTacOYjSRUqG8hppPbnfDo7O9XU1DQm9/O9e/fqmGOOGXKqau/evZo5c6bvNVd7H1GN9SeTSd12222j8vN+xTQ1NUmSOjo6MoaP2WtuAMaerq4unX322TmvwUydOjX1O58YXzZv3pxxvX8sqKpwS/+Jn1w/9wNgdHV2dqq9vX3IT8bt3btXmzdv9vRboKOp2vuIaqq/paUl42e2FixY4HdJGaoq3KZOnZrz/6PJ659XAcaDTZs26fjjj9c999yT8XuD7733nm644QZP8xjN95QffcRIqqb63aP3tra2MfnXKCb4XUAp/DgHXU3nvYHRNmnSJC1btkzLli0r+/rKaL6nqv39Wk3133DDDZ4/0Pihqo7cAADwgnADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYp6J/FWDLli2qra2tZJNAVduyZYvfJQBj2pYtW3L+odSKhdvEiRP1zDPP6JlnnqlUk8CoOvPMM0d93kuXLh21NgBbnHbaaUOGOaaa/oAQxoy+vj5dccUVOvPMMxWNRnXSSSf5XRLGGWOM7rjjDt177726++67deedd/pdEsYQwg1l++lPf6rLL79cjuNo+/btOuuss/wuCePEp59+qtWrV+vJJ59Ue3u7Vq5c6XdJGGO4oQRlO+uss/TKK6/oxBNP1IUXXqje3l6/S8I48NFHH+nLX/6ytm3bpmeffZZgQ06EG4ZlypQpev755/XFL35RX/rSl/T973/f75JgsVgsposuukhvv/22XnzxRS1YsMDvkjBGEW4Yts985jN66qmn9NWvflX19fX6x3/8R79LgoX+/d//XXPmzNGECRPU29ur8847z++SMIZV9KsAsFdNTY3uu+8+nXrqqVq7dq3effddtba26qij+PyE4duxY4fq6+t14YUX6sknn9Txxx/vd0kY4+h5MKJuvfVWdXV1aePGjVq6dKn+7//+z++SUOUefPBBBQIB1dfXa+vWrQQbPCHcMOKWLl2qH/3oR3r++ed1ySWX6L//+7/9LglVyBijUCikNWvWKBQK6aGHHuJHIOAZXwXAqBkYGNDll1+uCRMm6Nlnn9UZZ5zhd0moEp9++qluuOEGRSIRtbW16U//9E/9LglVhiM3jJqZM2eqt7dXkydP1oUXXqh/+Zd/8bskVIFkMqnLL79cTz/9tLZt20awoSyEG0bV1KlT9fzzz+uP//iPtWDBAn5+DQXt379fc+fO1cDAgF566SUtXLjQ75JQpQg3jLpjjz1WzzzzjFatWqUlS5bo/vvv97skjEG7d+/W7Nmz5TiO+vr6dP755/tdEqoYXwVARdTU1Oh73/ueTjnlFH3jG9/Qu+++q7/927+V4zh+l4Yx4Ec/+pGWLFmiL3zhC3ryySc1adIkv0tClePIDRX1rW99Sx0dHbr//vt17bXX6le/+pXfJcFnjzzyiK644gpdffXV2rZtG8GGEUG4oeIaGhr0wx/+UM8995wWLlyoDz/80O+S4ANjjO666y5dd911uu222/RP//RPmjhxot9lwRJ8FQC++clPfqLFixfr6KOP1rPPPpvzbzLBTgcOHNCaNWv0+OOP64EHHtB1113nd0mwDEdu8M3v//7vq7e3V8cee6zmzJmj1157ze+SUAG/+MUvtHjxYj311FPaunUrwYZRQbjBV7/zO7+jF154QRdccIHmz5+vaDTqd0kYRe+9954uuugi7dmzRy+88IK+/OUv+10SLEW4wXfHHXecfvCDH6ipqUlXX321NmzY4HdJGAVvvPGG5syZo0OHDqm3t1d/+Id/6HdJsBhfBcCYMGHCBD3wwAM65ZRTdOONNyoWi+mee+7hqwKWeO6557RkyRL90R/9kb7//e9r8uTJfpcEy3HkhjHljjvu0GOPPaa///u/V2Njoz755BO/S8IwPfroo1q8eLGuuOIK7dixg2BDRRBuGHOWL1+uHTt2aMeOHbr00kv10Ucf+V0SyvSXf/mXWr16tdatW6dNmzZxqz8qhq8CYMzas2ePFi1apOOOO07btm3Tqaee6ndJ8OjgwYP62te+pscee0zf/e53tWbNGr9LwjjDkRvGrHPOOUe9vb2aOHGi5syZo9dff93vkuDB//zP/+iKK67Q5s2b9YMf/IBggy8IN4xp06ZN065duzRr1iz9yZ/8ibZv3+53SSjg5z//uS6++GLt3r1b//zP/6xFixb5XRLGKcINY97xxx+vrVu3aunSpaqrq1NbW5vfJSGHPXv2aM6cOfr000/V29urCy64wO+SMI7xVQBUhQkTJuihhx7SqaeeqmAwqFgspvXr1/NVgTHi+eef11e+8hXNmjVLTz/9tE444QS/S8I4x5EbqkpLS4seeeQRhcNhrVixQp9++qnfJY17jz/+uC677DJddtll+uEPf0iwYUwg3FB1Vq1apW3btmnr1q267LLLlEgk/C5p3Pqrv/orrVy5UmvXrlVnZ6eOPvpov0sCJPFVAFSxN954Q4sWLdKkSZO0fft2zZgxw++Sxo2DBw/qxhtv1EMPPaT77rtPzc3NfpcEZCDcUNXef/99LVq0SP/1X/+lrVu38nuFFfC///u/uvbaa/XCCy8oEokoEAj4XRIwBKclUdWmT5+uF198Ueecc47mzZunHTt2+F2S1T744APNmzdPr7/+up5//nmCDWMW4Yaq99nPflbbtm3TNddco0AgoIcfftjvkqz0k5/8RLNnz9bHH3+s3t5eff7zn/e7JCAvvgoAK9TW1urhhx/WKaecoq9+9at699139Rd/8Rd8VWCEvPDCC7r66qt17rnn6plnntGJJ57od0lAQVxzg3UeeeQRfe1rX1NDQ4Pa29v5sd5hikQiWr16terq6vTYY4/pmGOO8bskoChOS8I6q1ev1tatW/X0009r0aJFSiaTOad744039OGHH1a4urFnz549yvcZ995771VTU5NuuukmPfHEEwQbqgbhBitdeumlevHFF/XWW2/poosu0nvvvZcxvqenR+eff/64vyGira1N5557rr71rW9lDD906JC+/vWv684779R3vvMdhcNhTvGiqnBaElbbv3+/Fi1apI8++kjbt2/X+eefrzfeeENz5szRxx9/LOnI9aSLL77Y50or71e/+pXOOOMM/fznP5ckfe9731Nzc7M+/vhjLVu2TD09Pero6NBVV13lc6VA6Thyg9VOPvlkvfTSS5o5c6bmzp2rSCSihQsXpv7C94QJE3TzzTfr8OHDPldaeX/3d3+neDyeen7TTTfp0Ucf1fz58/Xqq6+qp6eHYEPV4sgN48Knn36q66+/Xi+//LL279+vAwcOpMY5jqNHHnlEq1at8rHCyvrggw90xhln6Je//GVqmOM4qq2t1XnnnacnnnhCZ5xxho8VAsPDkRvGhZqaGn344YdDgs31zW9+M6Ojt11LS8uQ9WCM0aFDh/T222/nvcEEqBaEG8aFm266STt27MgZbMYYffjhh/qbv/kbHyqrvB//+Md6+OGHc66LQ4cO6eOPP9Yll1yi//zP//ShOmBkcFoS1vvzP/9z3X333UWnO/roo/X2229r+vTpFajKP/Pnz9dLL72kgwcP5p2mtrZWJ5xwgt58802+sI2qRLjBeu4t7I7jFDzdVltbq2uvvVabNm2qVGkVF41GVVdX53n6H//4xzrvvPNGsSJgdHBaEtb7xS9+oY0bN+qcc86RdCTEcjlw4IA6Ojr0r//6r5Usr2IOHDigtWvXqqamJuf4mpoaOY6jE044Qd/85jf105/+lGBD1eLIDePKq6++qgceeECdnZ06cOCADh8+nHE0N2HCBH3+85/XK6+84mOVo+M73/mO1q5dO+RrD7W1tTp48KDmzp2rr3/967r66qv5o6OoeoQbxqVkMqnHH39c3/3ud/Xmm2+qtrY24waLJ598Utdcc42PFY6sjz76SKeddlrqp8iOOurISZvjjjtO119/vdasWaOZM2f6WSIwogg3jHuvvPKKNm7cqCeeeEKHDh3SoUOHJB35BQ9bjmCamprU2dmpmpoaHTp0SLNnz9aNN96o+vp6a5YRSEe4WerVV1/VF77wBb/LAKxw5513av369X6XgRLw99ws9R//8R+SpM2bN/tcSXWKxWKaNm1a3ptPqs3PfvYzTZ8+nT//U4ampib97Gc/87sMlIhws1x9fb3fJQBV7ZlnnvG7BJSBrwIAAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7ihqiWTSTmOY2W7fX19amlpkeM4chxHLS0t2r17twYHB31ZZq9s3iaoHoQbqtquXbusbLelpUWPPvqoVqxYIWOMjDG6+eabtW/fPk2dOnVU2x4uW7cJqgt/iRtVK5lMqr293bp23SO07u7ujOFTpkxRIBBQb2+v5syZM2rtD4et2wTVhyM3ZEgmk+rq6kqdCsvVYeSaZnBwMDV+cHBQXV1dqqurkyRFo1E5jqO6ujrt27evpPbcTiv91JzbVjgcVjQalaTU+PQaWltbU+329PSUVNtItysdCa2WlpaC67+vr0/r16/XHXfckXea2bNnDxnGNilvm8BiBlbq6Ogw5WzeQCBgQqFQ6nkwGMx47k7T1tZmjDEmHo+bQCBgAoGASSQSqfGSjCTT29trjDEmFosZSSYYDJbUXjAYNJJMPB7POQ+3nXRuTZFIxBhjzM6dO40k09/f77m2kRZmqzQAABIaSURBVG7XGGNCodCQdZktFAql2i0F26S8beJFY2OjaWxs9Dw9xgbCzVLlhFskEhnSsfb29ppAIJB67nYO2dNISnUgxuTuaLKHeWkvFAoV7MBytePON7ttt4P2UttotOtFrvkWwzYpv10vCLfqRLhZqpxwcz9BF+J+ek6XSCSMpIwO0Etn5aU9VywWM+Fw2FOHln4kkP3wWttotOtFOeHGNim/XS8It+pEuFmqnHDz8qbPN42XjsbLNLm0tbWZQCBgBgYGymrHyzLkGjbS7XrhBpV7OtELtkn57XpBuFUnws1SwzlyK3Q9wp0m+5qQVPz6R76jhELtuaeVYrFYznkUamdgYCDnPL3UNhrtetHd3V10nWRjm5TfrheEW3XibkmkBAIBSdLGjRuVTCYlSfv27VNzc3NqmsbGRknSO++8kxrmTltfXz/i7TU0NEiSZsyY4Xm+bW1tkqRNmzal5uveMeeVX+0GAgEFAgFt3Lgx7zT79u3LmCfbZHTbRZXyO10xOso5cnPvLFPadYlgMJjxqTeRSKTuxHOPFCKRSMYRQjweT73ePb3mXgNS2hGGl/bc8bFYLONUlDuP9KOWcDg8pP30RywW81zbSLdrjLe7JdPXS/a6MObI9ab0dc82Gd428YIjt+pEuFmq3K8CxOPx1O3ooVAo5+mceDxu2traUh1FJBLJuEaU3ZHkG+alvf7+/tQ4d9pgMJjqnLLHu2KxWGq+6dN7rW2k2zXGe7gZc6Rz7+7uTl2Dk5S63T9Xx8w2KW+beEG4VSfHGGME63R2dqqpqUlsXmB4mpqaJEkdHR0+V4JScM0NAGAdwg0AYB3CDQBgHcINAGAdwg0AYB3CDQBgHcINAGAdwg0AYB3CDQBgHcINAGAdwg0AYB3CDQBgHcINAGAdwg0AYB3CDQBgHcINAGAdwg0AYJ0JfheA0fGZz3xGkuQ4js+VANVv9erVfpeAEjnGGON3ERh5Bw8eVHd3tw4dOuR3KShg6dKl+sY3vqG5c+f6XQoKmD17tk4++WS/y0AJCDfAR47jqKOjQ42NjX6XAliFa24AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA60zwuwBgPPnoo4+GDPv4448zhh977LGaOHFiJcsCrOMYY4zfRQDjwW233aZ777236HQTJ07UJ598UoGKAHtxWhKokNNPP93TdGedddYoVwLYj3ADKmTJkiWaMKHwlYCamhr92Z/9WYUqAuxFuAEVcuKJJ2rhwoWqqanJO81RRx2lr3zlKxWsCrAT4QZU0PLly5XvMveECRN0+eWXa/LkyRWuCrAP4QZU0JVXXpn3TshDhw5pxYoVFa4IsBPhBlTQscceq6uuukq1tbVDxh1zzDFavHixD1UB9iHcgApramrSgQMHMobV1tbqmmuu0W/91m/5VBVgF8INqLBLL71Un/3sZzOGHThwQE1NTT5VBNiHcAMqbOLEibr22mszTk2ecMIJuuSSS3ysCrAL4Qb4IP3UZG1trZYtW1b0O3AAvOPntwAfHD58WNOmTVM8Hpckvfjii5o7d67PVQH24MgN8MFRRx2VusY2bdo0ffGLX/S5IsAunAdB1YlGo9q0aZPfZQyb+5cADh8+rGuvvdbnaobvzDPP1F//9V/7XQYgidOSqEJNTU3q7OxUfX2936UM25tvvqnp06cPuXuy2mzZskWS8v76ClBpHLmhKjU2Nqqjo8PvMvBrnZ2dfJUBYwrX3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwAANYh3AAA1iHcAADWIdwwrvT19am5uVmO46i5uVm7d+/2uyQAo4Bww7jR09OjOXPm6Pbbb5cxRvPmzVNLS0vR1yWTSfX19am9vV11dXVlte04Tt5Ha2urotGokslkWfMGMBThhnHD/WvRM2bMkCQtW7ZM3d3dRV8XDoe1bds2rVmzRtFotKy2jTGKx+Op54lEQsYYGWN0ySWXqL29XStWrNDg4GBZ8weQyTH8XXhUGfcvPpf6l7gdx5F0JGjKMdzXF5rH4OCgrr/+eknSpk2bNGnSpLLb8IP7l7jpTjBWcOQG67mn//I9TyaT6urqSg1vb28vuY2WlhZPpzjzmTJlim655RZFo1Ht2rUrY9zg4KBaW1vlOI7q6urU09OTGt7V1ZU6VRqNRlPT7Nu3L2Me7uvb29s1ODiYsfyF2gCqFeEG67mn//I9X7Fihfbs2ZMa/m//9m/DCqpyXXDBBZKk7du3p4a5R3TTp0+XMUa33HKLvvSlL2n37t26/vrr1dDQoGg0qr6+PgUCAcViMUWjUd1zzz2pebS2tqq+vl7GGC1dulT33XdfRruF2gCqlgGqTGNjo2lsbCz5dZJM9i4fiUSMJBOPx1PDent7TSAQ8PT6kaih0Hi3vuxpQqFQ3vllD8tevng8XlIbXnR0dAx73QAjiSM3jGudnZ2SjpwWdM2ePdvTjSaV4NaXfnelJK1fv97zPILBoKZOnaquri4lk0lNmTIl48h1JNoAxhrCDeNauXc/jgb3qwChUCg1zK3P/PqUafrDq7Vr1yoQCKihoUGTJ09Wa2trxviRaAMYawg3jGuBQECSxsT1pddff12SNH/+/CHj9u7dW/Z8zz77bHV3d6u/v1/BYFDr1q0bEnDDbQMYawg3jGtuuG3cuDF15LRv3z41NzdXtI7BwUH9wz/8gwKBgBYsWJAa3tbWJunI1wPc+tw7G71yHEfJZFKzZs3Shg0b1N/fr3Xr1o1oG8CY49O1PqBs5dxQ0t/fn7rRYmBgIDU8Ho+bQCCQGifJBIPBjGmMMSaRSKTGJxKJIfMPhUJFb8DIN4/+/n4TCARMIBDIuPHDrS+9NvcRi8UyxrnzS2/DnZd+fXNILBYzxhgTi8VMOBz21IZX3FCCsYYjN1jPcRz9wR/8Qer5zJkzUzdNTJkyRQ8++GDqOlcoFNLatWt19tlnZ7x+8uTJqeeTJ08e8j0xLzXkmofjOHruued0xx13qLu7O+PGFre+WCyWqi8YDCoWi2nGjBmaOnVqxvzS/5WUMf7mm2/Wli1b5DiOtmzZoltvvdVTG0C14hdKUHXK/YUSjB5+oQRjDUduAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOsQbgAA6xBuAADrEG4AAOtM8LsAoBydnZ06cOCA32Xg17Zs2eJ3CUAGwg1VZ9myZdYE265du/R7v/d7mjJlit+lDEt9fb3OPPNMv8sAUhxjjPG7CGC8chxHHR0damxs9LsUwCpccwMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFiHcAMAWIdwAwBYh3ADAFjHMcYYv4sAxoOnnnpKt99+u6ZNm5Ya9vLLL2vmzJn63Oc+J0lKJBKaO3eu7r//fr/KBKxAuAEV0tLSovXr13ualrclMDyclgQqpKGhoeg0tbW1uuuuu0a/GMByHLkBFXTuuedqz549Bad56623NHPmzApVBNiJIzeggpYvX67a2tqc4xzH0fnnn0+wASOAcAMqqKGhQQcPHsw5rqamRqtWrapwRYCdOC0JVNjs2bP12muv6fDhwxnDHcfR/v37NX36dJ8qA+zBkRtQYatWrZLjOBnDjjrqKF144YUEGzBCCDegwpYsWTJkmOM4WrlypQ/VAHYi3IAKO+mkkzR//nzV1NSkhjmOkzP0AJSHcAN8sHLlytQXtWtqarRw4UKdeOKJPlcF2INwA3xw1VVXpb4SYIzR8uXLfa4IsAvhBvjg+OOP1+LFiyVJEydO1JVXXulzRYBdJvhdAMa+/fv3q6+vz+8yrHP66aen/t2+fbvP1djnd3/3dzVnzhy/y4BP+J4birruuuv0yCOP+F0GUDK6t/GL05Io6pNPPlFjY6OMMTx4VMWjo6PD77cNfEa4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuMEXg4OD6urqUl1dXcXabGlpUUtLy5DhfX19am5uluM4am5uVnNzc87pKlUPgOEj3OCLb3/722poaFA0GvW1jp6eHs2ZM0e33367jDGaN2+e3n///RFvJ5lMynGcEZ9vuRzHyftobW1VNBpVMpn0u0ygbPwlbhTV1NQkSSP+ByDdzt7PXbC5uVkbN24c9Rqi0ajq6up8XdZsg4ODmjp1qiQpkUho0qRJkqTdu3enjigffPBBTZkyxbcay9XZ2ammpqYxtb5RWRy5YVzbuHHjqLeRTCbV3t4+6u2UKj203GCTpFmzZunBBx+UJF1//fUcwaEqEW4YNclkUl1dXanTXcU6eDcE3OlbWlo0ODiYMU1ra2tqXoODg0NO9eUbn32Nz23D5T7Pdy2w2LIUqj0cDqdOv5bTTvo6yH5dNBqV4ziqq6vTvn37UtMN93relClTdMsttygajWrXrl0Z4wYHB1Prua6uTj09PSXVJhXfjvnaADwzQBGNjY2msbGx5NcFAgETCoVSz4PBYMZzSSZ9FwwGg0aSicfjJhaLGUkmGAymxofDYROLxYwxxiQSCRMKhTJeX2h8IBAY0l6uGvJNV2xZitVeSjttbW3GGGPi8bgJBAImEAiYRCIx5HW9vb3GGJOzvVAolFFfPrlqcCUSiSHzdWuKRCLGGGN27txpJJn+/n7PtRXbjoXa8KqjoyPvcmF8YOujqHLCLRKJpDp7V29vrwkEAqnn2R1rKBQqGAjZ84vH4yWPLxZuuYZ5WRYvtRdrx+3Es9uRlOroS1kOL4q9Lt+6yJ7GDVIvtRXbTsXa8IJwA1sfRZUTbu6n+ELydayxWMyEw+G8R3aRSCR1JJOu2Phyw83LshSr3Us7bv3p3KOnQh8K8g3zotRwSz86y36Uupz5tlOxNrwg3MDWR1HlhJuXzijXNG1tbSYQCJiBgYEh4wcGBjI6vnA4nPHaYuPLDTevHWuh2ofTTjnz8qrQ69xgLXQq2cv8St2O5S5LOsINbH0UNZwjt0LXSfKd8nKvx+Tr5Pr7+1Of/rM7xkLjh3vkVmhZitVeSjvpp+zc6Qqd8sw3zItCr3NPk+7cuXPI9AMDA57nV+p2LNaGF4Qb2Pooqpxwa2trS3XK7qmnWCxW0nWpXM/TT2P19/eXPL6ccBuNZck1zA1I92YMY35z9JQrYIothxf5Xpd+M0s6d12EQqHUuojH46lw8nqEWmg7FWvDC8INbH0UVU64uZ2j27G54eB+GndvIkg/UnGnj8ViGaf23PFuh+ceHbnXt1yFxudqz+1U048Sck1XbFm81J5+VBYOh3O2k0gkUoHiDotEIkPuVnRf53b8bgCmz8vL3ZLpr8sOm+w6crWf/ojFYp5rK7YdC7XhFeEGtj6KKverAPF4PHWbdygUygiD7I7LmN+ETSgUSr02GAxmnOpzwyH7VFax8bk6Sy8PL8vipfbs8YXacY9cpKE3XeR6Xa5hxcKt0DKHw+GMo8dssVgstS6yt4+X2optx0JteEW4gZ/fQlGj9fNbwGjh57fAL5QAAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArEO4AQCsQ7gBAKxDuAEArDPB7wJQHbZs2aKrrrrK7zIAT7Zs2eJ3CfAZ4YaiTjvtNB04cEBLly71uxTAs4kTJ/pdAnzkGGOM30UAADCSuOYGALAO4QYAsA7hBgCwDuEGALDO/wO4ObXJTY7fIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acute-teach",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 759 steps, validate for 365 steps\n",
      "Epoch 1/200\n",
      "759/759 [==============================] - 64s 85ms/step - loss: 3.1449 - accuracy: 0.2943 - val_loss: 2.5358 - val_accuracy: 0.3251\n",
      "Epoch 2/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 2.3698 - accuracy: 0.3449 - val_loss: 2.2718 - val_accuracy: 0.3541\n",
      "Epoch 3/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 2.0679 - accuracy: 0.3783 - val_loss: 2.0107 - val_accuracy: 0.3815\n",
      "Epoch 4/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.8427 - accuracy: 0.4071 - val_loss: 1.8744 - val_accuracy: 0.4052\n",
      "Epoch 5/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.7131 - accuracy: 0.4302 - val_loss: 1.8177 - val_accuracy: 0.4116\n",
      "Epoch 6/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.6295 - accuracy: 0.4436 - val_loss: 1.7733 - val_accuracy: 0.4203\n",
      "Epoch 7/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.5655 - accuracy: 0.4560 - val_loss: 1.7573 - val_accuracy: 0.4239\n",
      "Epoch 8/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.5181 - accuracy: 0.4668 - val_loss: 1.7309 - val_accuracy: 0.4356\n",
      "Epoch 9/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.4768 - accuracy: 0.4765 - val_loss: 1.7382 - val_accuracy: 0.4376\n",
      "Epoch 10/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.4422 - accuracy: 0.4858 - val_loss: 1.7318 - val_accuracy: 0.4400\n",
      "Epoch 11/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.4105 - accuracy: 0.4926 - val_loss: 1.7501 - val_accuracy: 0.4395\n",
      "Epoch 12/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.3823 - accuracy: 0.4984 - val_loss: 1.7454 - val_accuracy: 0.4450\n",
      "Epoch 13/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.3580 - accuracy: 0.5050 - val_loss: 1.7439 - val_accuracy: 0.4405\n",
      "Epoch 14/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.3312 - accuracy: 0.5107 - val_loss: 1.7598 - val_accuracy: 0.4445\n",
      "Epoch 15/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.3107 - accuracy: 0.5158 - val_loss: 1.7780 - val_accuracy: 0.4449\n",
      "Epoch 16/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.2875 - accuracy: 0.5212 - val_loss: 1.7911 - val_accuracy: 0.4486\n",
      "Epoch 17/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.2660 - accuracy: 0.5265 - val_loss: 1.7853 - val_accuracy: 0.4484\n",
      "Epoch 18/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.2453 - accuracy: 0.5318 - val_loss: 1.7962 - val_accuracy: 0.4481\n",
      "Epoch 19/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.2279 - accuracy: 0.5365 - val_loss: 1.8257 - val_accuracy: 0.4469\n",
      "Epoch 20/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 1.2096 - accuracy: 0.5409 - val_loss: 1.8597 - val_accuracy: 0.4490\n",
      "Epoch 21/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1923 - accuracy: 0.5443 - val_loss: 1.8814 - val_accuracy: 0.4477\n",
      "Epoch 22/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1721 - accuracy: 0.5507 - val_loss: 1.9148 - val_accuracy: 0.4450\n",
      "Epoch 23/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1567 - accuracy: 0.5551 - val_loss: 1.9214 - val_accuracy: 0.4459\n",
      "Epoch 24/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1409 - accuracy: 0.5588 - val_loss: 1.9376 - val_accuracy: 0.4466\n",
      "Epoch 25/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1240 - accuracy: 0.5637 - val_loss: 1.9414 - val_accuracy: 0.4463\n",
      "Epoch 26/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.1062 - accuracy: 0.5678 - val_loss: 1.9883 - val_accuracy: 0.4426\n",
      "Epoch 27/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0934 - accuracy: 0.5713 - val_loss: 2.0084 - val_accuracy: 0.4447\n",
      "Epoch 28/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0782 - accuracy: 0.5757 - val_loss: 2.0382 - val_accuracy: 0.4474\n",
      "Epoch 29/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0648 - accuracy: 0.5800 - val_loss: 2.0742 - val_accuracy: 0.4459\n",
      "Epoch 30/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0502 - accuracy: 0.5840 - val_loss: 2.0546 - val_accuracy: 0.4422\n",
      "Epoch 31/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0354 - accuracy: 0.5889 - val_loss: 2.1158 - val_accuracy: 0.4440\n",
      "Epoch 32/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0219 - accuracy: 0.5932 - val_loss: 2.1489 - val_accuracy: 0.4433\n",
      "Epoch 33/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 1.0109 - accuracy: 0.5965 - val_loss: 2.1840 - val_accuracy: 0.4438\n",
      "Epoch 34/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9996 - accuracy: 0.5990 - val_loss: 2.1980 - val_accuracy: 0.4425\n",
      "Epoch 35/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9860 - accuracy: 0.6031 - val_loss: 2.2443 - val_accuracy: 0.4423\n",
      "Epoch 36/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9732 - accuracy: 0.6081 - val_loss: 2.3004 - val_accuracy: 0.4447\n",
      "Epoch 37/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9582 - accuracy: 0.6128 - val_loss: 2.3072 - val_accuracy: 0.4415\n",
      "Epoch 38/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9514 - accuracy: 0.6145 - val_loss: 2.3584 - val_accuracy: 0.4416\n",
      "Epoch 39/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9384 - accuracy: 0.6187 - val_loss: 2.4177 - val_accuracy: 0.4415\n",
      "Epoch 40/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9297 - accuracy: 0.6220 - val_loss: 2.3817 - val_accuracy: 0.4413\n",
      "Epoch 41/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9138 - accuracy: 0.6280 - val_loss: 2.4459 - val_accuracy: 0.4397\n",
      "Epoch 42/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.9090 - accuracy: 0.6290 - val_loss: 2.4335 - val_accuracy: 0.4432\n",
      "Epoch 43/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8942 - accuracy: 0.6349 - val_loss: 2.5188 - val_accuracy: 0.4403\n",
      "Epoch 44/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8879 - accuracy: 0.6360 - val_loss: 2.5495 - val_accuracy: 0.4405\n",
      "Epoch 45/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8757 - accuracy: 0.6407 - val_loss: 2.5445 - val_accuracy: 0.4422\n",
      "Epoch 46/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8694 - accuracy: 0.6434 - val_loss: 2.6414 - val_accuracy: 0.4393\n",
      "Epoch 47/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8589 - accuracy: 0.6465 - val_loss: 2.6758 - val_accuracy: 0.4421\n",
      "Epoch 48/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8521 - accuracy: 0.6493 - val_loss: 2.7205 - val_accuracy: 0.4398\n",
      "Epoch 49/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.8388 - accuracy: 0.6544 - val_loss: 2.7085 - val_accuracy: 0.4406\n",
      "Epoch 50/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8337 - accuracy: 0.6555 - val_loss: 2.7643 - val_accuracy: 0.4414\n",
      "Epoch 51/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8236 - accuracy: 0.6592 - val_loss: 2.8315 - val_accuracy: 0.4374\n",
      "Epoch 52/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8147 - accuracy: 0.6621 - val_loss: 2.8539 - val_accuracy: 0.4386\n",
      "Epoch 53/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.8065 - accuracy: 0.6659 - val_loss: 2.9243 - val_accuracy: 0.4389\n",
      "Epoch 54/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7983 - accuracy: 0.6687 - val_loss: 2.8986 - val_accuracy: 0.4345\n",
      "Epoch 55/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.7936 - accuracy: 0.6699 - val_loss: 2.9242 - val_accuracy: 0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7875 - accuracy: 0.6727 - val_loss: 2.9780 - val_accuracy: 0.4371\n",
      "Epoch 57/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7805 - accuracy: 0.6760 - val_loss: 3.0071 - val_accuracy: 0.4357\n",
      "Epoch 58/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7687 - accuracy: 0.6805 - val_loss: 3.1026 - val_accuracy: 0.4320\n",
      "Epoch 59/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7680 - accuracy: 0.6806 - val_loss: 3.1363 - val_accuracy: 0.4356\n",
      "Epoch 60/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7558 - accuracy: 0.6856 - val_loss: 3.1538 - val_accuracy: 0.4350\n",
      "Epoch 61/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7516 - accuracy: 0.6869 - val_loss: 3.1609 - val_accuracy: 0.4366\n",
      "Epoch 62/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7440 - accuracy: 0.6905 - val_loss: 3.2832 - val_accuracy: 0.4334\n",
      "Epoch 63/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7415 - accuracy: 0.6912 - val_loss: 3.2266 - val_accuracy: 0.4337\n",
      "Epoch 64/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7353 - accuracy: 0.6937 - val_loss: 3.2849 - val_accuracy: 0.4370\n",
      "Epoch 65/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7269 - accuracy: 0.6973 - val_loss: 3.3020 - val_accuracy: 0.4328\n",
      "Epoch 66/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7178 - accuracy: 0.7006 - val_loss: 3.3386 - val_accuracy: 0.4341\n",
      "Epoch 67/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7123 - accuracy: 0.7026 - val_loss: 3.4194 - val_accuracy: 0.4333\n",
      "Epoch 68/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7096 - accuracy: 0.7042 - val_loss: 3.4922 - val_accuracy: 0.4327\n",
      "Epoch 69/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7045 - accuracy: 0.7061 - val_loss: 3.4817 - val_accuracy: 0.4331\n",
      "Epoch 70/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.7013 - accuracy: 0.7080 - val_loss: 3.5076 - val_accuracy: 0.4324\n",
      "Epoch 71/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6907 - accuracy: 0.7117 - val_loss: 3.5998 - val_accuracy: 0.4317\n",
      "Epoch 72/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6847 - accuracy: 0.7139 - val_loss: 3.6061 - val_accuracy: 0.4317\n",
      "Epoch 73/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6820 - accuracy: 0.7159 - val_loss: 3.6084 - val_accuracy: 0.4324\n",
      "Epoch 74/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6762 - accuracy: 0.7185 - val_loss: 3.7001 - val_accuracy: 0.4319\n",
      "Epoch 75/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6764 - accuracy: 0.7183 - val_loss: 3.6758 - val_accuracy: 0.4334\n",
      "Epoch 76/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6665 - accuracy: 0.7218 - val_loss: 3.8377 - val_accuracy: 0.4294\n",
      "Epoch 77/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6618 - accuracy: 0.7251 - val_loss: 3.8545 - val_accuracy: 0.4325\n",
      "Epoch 78/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6551 - accuracy: 0.7271 - val_loss: 3.8691 - val_accuracy: 0.4288\n",
      "Epoch 79/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6542 - accuracy: 0.7281 - val_loss: 3.9279 - val_accuracy: 0.4297\n",
      "Epoch 80/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6423 - accuracy: 0.7320 - val_loss: 3.8566 - val_accuracy: 0.4304\n",
      "Epoch 81/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6483 - accuracy: 0.7303 - val_loss: 3.9905 - val_accuracy: 0.4303\n",
      "Epoch 82/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6371 - accuracy: 0.7346 - val_loss: 3.9944 - val_accuracy: 0.4322\n",
      "Epoch 83/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.6355 - accuracy: 0.7359 - val_loss: 3.9980 - val_accuracy: 0.4294\n",
      "Epoch 84/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6297 - accuracy: 0.7383 - val_loss: 4.0537 - val_accuracy: 0.4277\n",
      "Epoch 85/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6306 - accuracy: 0.7383 - val_loss: 4.0524 - val_accuracy: 0.4287\n",
      "Epoch 86/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6252 - accuracy: 0.7407 - val_loss: 4.1392 - val_accuracy: 0.4288\n",
      "Epoch 87/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6173 - accuracy: 0.7435 - val_loss: 4.1685 - val_accuracy: 0.4260\n",
      "Epoch 88/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6115 - accuracy: 0.7459 - val_loss: 4.2326 - val_accuracy: 0.4276\n",
      "Epoch 89/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.6107 - accuracy: 0.7472 - val_loss: 4.2790 - val_accuracy: 0.4296\n",
      "Epoch 90/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6078 - accuracy: 0.7479 - val_loss: 4.3198 - val_accuracy: 0.4291\n",
      "Epoch 91/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.6016 - accuracy: 0.7510 - val_loss: 4.3436 - val_accuracy: 0.4284\n",
      "Epoch 92/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.6006 - accuracy: 0.7520 - val_loss: 4.3897 - val_accuracy: 0.4276\n",
      "Epoch 93/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5942 - accuracy: 0.7545 - val_loss: 4.4436 - val_accuracy: 0.4272\n",
      "Epoch 94/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5911 - accuracy: 0.7558 - val_loss: 4.3511 - val_accuracy: 0.4291\n",
      "Epoch 95/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5864 - accuracy: 0.7581 - val_loss: 4.5164 - val_accuracy: 0.4263\n",
      "Epoch 96/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5862 - accuracy: 0.7583 - val_loss: 4.5659 - val_accuracy: 0.4268\n",
      "Epoch 97/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5743 - accuracy: 0.7629 - val_loss: 4.4788 - val_accuracy: 0.4259\n",
      "Epoch 98/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5801 - accuracy: 0.7608 - val_loss: 4.6042 - val_accuracy: 0.4247\n",
      "Epoch 99/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5745 - accuracy: 0.7633 - val_loss: 4.6740 - val_accuracy: 0.4268\n",
      "Epoch 100/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5650 - accuracy: 0.7668 - val_loss: 4.7672 - val_accuracy: 0.4255\n",
      "Epoch 101/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5658 - accuracy: 0.7664 - val_loss: 4.7075 - val_accuracy: 0.4261\n",
      "Epoch 102/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5676 - accuracy: 0.7672 - val_loss: 4.7542 - val_accuracy: 0.4266\n",
      "Epoch 103/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5636 - accuracy: 0.7691 - val_loss: 4.7986 - val_accuracy: 0.4247\n",
      "Epoch 104/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5606 - accuracy: 0.7703 - val_loss: 4.7259 - val_accuracy: 0.4251\n",
      "Epoch 105/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5546 - accuracy: 0.7728 - val_loss: 4.8888 - val_accuracy: 0.4273\n",
      "Epoch 106/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5556 - accuracy: 0.7721 - val_loss: 4.7618 - val_accuracy: 0.4265\n",
      "Epoch 107/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5499 - accuracy: 0.7744 - val_loss: 4.9502 - val_accuracy: 0.4268\n",
      "Epoch 108/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5444 - accuracy: 0.7776 - val_loss: 5.0278 - val_accuracy: 0.4243\n",
      "Epoch 109/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5340 - accuracy: 0.7811 - val_loss: 5.0544 - val_accuracy: 0.4233\n",
      "Epoch 110/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5338 - accuracy: 0.7814 - val_loss: 5.0867 - val_accuracy: 0.4247\n",
      "Epoch 111/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.5444 - accuracy: 0.7781 - val_loss: 5.1209 - val_accuracy: 0.4236\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5342 - accuracy: 0.7822 - val_loss: 5.2112 - val_accuracy: 0.4232\n",
      "Epoch 113/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5289 - accuracy: 0.7842 - val_loss: 5.0495 - val_accuracy: 0.4247\n",
      "Epoch 114/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5247 - accuracy: 0.7849 - val_loss: 5.2519 - val_accuracy: 0.4222\n",
      "Epoch 115/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5242 - accuracy: 0.7867 - val_loss: 5.2388 - val_accuracy: 0.4246\n",
      "Epoch 116/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5263 - accuracy: 0.7857 - val_loss: 5.2114 - val_accuracy: 0.4231\n",
      "Epoch 117/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5208 - accuracy: 0.7882 - val_loss: 5.2501 - val_accuracy: 0.4219\n",
      "Epoch 118/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5186 - accuracy: 0.7893 - val_loss: 5.3403 - val_accuracy: 0.4218\n",
      "Epoch 119/200\n",
      "759/759 [==============================] - 52s 69ms/step - loss: 0.5094 - accuracy: 0.7928 - val_loss: 5.3139 - val_accuracy: 0.4226\n",
      "Epoch 120/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5143 - accuracy: 0.7908 - val_loss: 5.3552 - val_accuracy: 0.4214\n",
      "Epoch 121/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5098 - accuracy: 0.7935 - val_loss: 5.4435 - val_accuracy: 0.4241\n",
      "Epoch 122/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4982 - accuracy: 0.7970 - val_loss: 5.5172 - val_accuracy: 0.4235\n",
      "Epoch 123/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5053 - accuracy: 0.7955 - val_loss: 5.4356 - val_accuracy: 0.4235\n",
      "Epoch 124/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.5127 - accuracy: 0.7925 - val_loss: 5.5537 - val_accuracy: 0.4233\n",
      "Epoch 125/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4988 - accuracy: 0.7978 - val_loss: 5.4819 - val_accuracy: 0.4245\n",
      "Epoch 126/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4978 - accuracy: 0.7980 - val_loss: 5.5135 - val_accuracy: 0.4232\n",
      "Epoch 127/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4899 - accuracy: 0.8021 - val_loss: 5.5545 - val_accuracy: 0.4237\n",
      "Epoch 128/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4949 - accuracy: 0.8006 - val_loss: 5.7604 - val_accuracy: 0.4225\n",
      "Epoch 129/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4898 - accuracy: 0.8021 - val_loss: 5.7627 - val_accuracy: 0.4211\n",
      "Epoch 130/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4891 - accuracy: 0.8021 - val_loss: 5.7536 - val_accuracy: 0.4203\n",
      "Epoch 131/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4877 - accuracy: 0.8035 - val_loss: 5.6916 - val_accuracy: 0.4214\n",
      "Epoch 132/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4824 - accuracy: 0.8055 - val_loss: 5.8159 - val_accuracy: 0.4222\n",
      "Epoch 133/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4860 - accuracy: 0.8047 - val_loss: 5.7895 - val_accuracy: 0.4187\n",
      "Epoch 134/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4742 - accuracy: 0.8087 - val_loss: 5.8643 - val_accuracy: 0.4201\n",
      "Epoch 135/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4810 - accuracy: 0.8067 - val_loss: 5.9224 - val_accuracy: 0.4205\n",
      "Epoch 136/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4785 - accuracy: 0.8086 - val_loss: 6.0261 - val_accuracy: 0.4240\n",
      "Epoch 137/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4684 - accuracy: 0.8118 - val_loss: 6.0485 - val_accuracy: 0.4178\n",
      "Epoch 138/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4673 - accuracy: 0.8120 - val_loss: 6.0537 - val_accuracy: 0.4213\n",
      "Epoch 139/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4692 - accuracy: 0.8119 - val_loss: 6.1139 - val_accuracy: 0.4199\n",
      "Epoch 140/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4662 - accuracy: 0.8129 - val_loss: 5.9365 - val_accuracy: 0.4182\n",
      "Epoch 141/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4635 - accuracy: 0.8150 - val_loss: 6.1684 - val_accuracy: 0.4209\n",
      "Epoch 142/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4648 - accuracy: 0.8144 - val_loss: 6.1495 - val_accuracy: 0.4207\n",
      "Epoch 143/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4615 - accuracy: 0.8151 - val_loss: 6.1053 - val_accuracy: 0.4190\n",
      "Epoch 144/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4623 - accuracy: 0.8151 - val_loss: 6.3131 - val_accuracy: 0.4188\n",
      "Epoch 145/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4651 - accuracy: 0.8145 - val_loss: 6.2754 - val_accuracy: 0.4201\n",
      "Epoch 146/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4614 - accuracy: 0.8163 - val_loss: 6.3001 - val_accuracy: 0.4217\n",
      "Epoch 147/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4448 - accuracy: 0.8218 - val_loss: 6.2215 - val_accuracy: 0.4195\n",
      "Epoch 148/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4473 - accuracy: 0.8212 - val_loss: 6.2791 - val_accuracy: 0.4196\n",
      "Epoch 149/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4474 - accuracy: 0.8217 - val_loss: 6.3904 - val_accuracy: 0.4174\n",
      "Epoch 150/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4501 - accuracy: 0.8212 - val_loss: 6.4645 - val_accuracy: 0.4197\n",
      "Epoch 151/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4555 - accuracy: 0.8189 - val_loss: 6.4341 - val_accuracy: 0.4181\n",
      "Epoch 152/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4386 - accuracy: 0.8256 - val_loss: 6.4625 - val_accuracy: 0.4173\n",
      "Epoch 153/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4387 - accuracy: 0.8257 - val_loss: 6.5260 - val_accuracy: 0.4186\n",
      "Epoch 154/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4400 - accuracy: 0.8247 - val_loss: 6.6653 - val_accuracy: 0.4198\n",
      "Epoch 155/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4405 - accuracy: 0.8256 - val_loss: 6.5548 - val_accuracy: 0.4191\n",
      "Epoch 156/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4456 - accuracy: 0.8240 - val_loss: 6.7346 - val_accuracy: 0.4185\n",
      "Epoch 157/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4372 - accuracy: 0.8263 - val_loss: 6.5876 - val_accuracy: 0.4184\n",
      "Epoch 158/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4401 - accuracy: 0.8261 - val_loss: 6.6283 - val_accuracy: 0.4194\n",
      "Epoch 159/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4377 - accuracy: 0.8268 - val_loss: 6.6665 - val_accuracy: 0.4173\n",
      "Epoch 160/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4302 - accuracy: 0.8295 - val_loss: 6.6500 - val_accuracy: 0.4199\n",
      "Epoch 161/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4263 - accuracy: 0.8308 - val_loss: 6.8418 - val_accuracy: 0.4216\n",
      "Epoch 162/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4356 - accuracy: 0.8280 - val_loss: 6.8559 - val_accuracy: 0.4196\n",
      "Epoch 163/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4197 - accuracy: 0.8340 - val_loss: 6.8823 - val_accuracy: 0.4190\n",
      "Epoch 164/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4262 - accuracy: 0.8318 - val_loss: 6.9729 - val_accuracy: 0.4199\n",
      "Epoch 165/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4351 - accuracy: 0.8295 - val_loss: 6.8645 - val_accuracy: 0.4179\n",
      "Epoch 166/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4225 - accuracy: 0.8342 - val_loss: 6.9773 - val_accuracy: 0.4174\n",
      "Epoch 167/200\n",
      "759/759 [==============================] - 51s 68ms/step - loss: 0.4257 - accuracy: 0.8325 - val_loss: 6.9450 - val_accuracy: 0.4175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4242 - accuracy: 0.8336 - val_loss: 7.0192 - val_accuracy: 0.4188\n",
      "Epoch 169/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4187 - accuracy: 0.8354 - val_loss: 7.1428 - val_accuracy: 0.4184\n",
      "Epoch 170/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4171 - accuracy: 0.8365 - val_loss: 6.9500 - val_accuracy: 0.4155\n",
      "Epoch 171/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4127 - accuracy: 0.8375 - val_loss: 7.1936 - val_accuracy: 0.4183\n",
      "Epoch 172/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4104 - accuracy: 0.8385 - val_loss: 7.0792 - val_accuracy: 0.4156\n",
      "Epoch 173/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4150 - accuracy: 0.8376 - val_loss: 6.9637 - val_accuracy: 0.4161\n",
      "Epoch 174/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4146 - accuracy: 0.8373 - val_loss: 7.0816 - val_accuracy: 0.4172\n",
      "Epoch 175/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4133 - accuracy: 0.8378 - val_loss: 7.0753 - val_accuracy: 0.4162\n",
      "Epoch 176/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4093 - accuracy: 0.8392 - val_loss: 7.2907 - val_accuracy: 0.4173\n",
      "Epoch 177/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4062 - accuracy: 0.8410 - val_loss: 7.3280 - val_accuracy: 0.4184\n",
      "Epoch 178/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4045 - accuracy: 0.8417 - val_loss: 7.2886 - val_accuracy: 0.4176\n",
      "Epoch 179/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4012 - accuracy: 0.8427 - val_loss: 7.3354 - val_accuracy: 0.4159\n",
      "Epoch 180/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4091 - accuracy: 0.8409 - val_loss: 7.4221 - val_accuracy: 0.4138\n",
      "Epoch 181/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4141 - accuracy: 0.8395 - val_loss: 7.3226 - val_accuracy: 0.4151\n",
      "Epoch 182/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4007 - accuracy: 0.8434 - val_loss: 7.3370 - val_accuracy: 0.4180\n",
      "Epoch 183/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4023 - accuracy: 0.8435 - val_loss: 7.4374 - val_accuracy: 0.4187\n",
      "Epoch 184/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3983 - accuracy: 0.8447 - val_loss: 7.4822 - val_accuracy: 0.4164\n",
      "Epoch 185/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4014 - accuracy: 0.8442 - val_loss: 7.5035 - val_accuracy: 0.4181\n",
      "Epoch 186/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3949 - accuracy: 0.8459 - val_loss: 7.5614 - val_accuracy: 0.4150\n",
      "Epoch 187/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3925 - accuracy: 0.8469 - val_loss: 7.6910 - val_accuracy: 0.4171\n",
      "Epoch 188/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4025 - accuracy: 0.8440 - val_loss: 7.5794 - val_accuracy: 0.4156\n",
      "Epoch 189/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3994 - accuracy: 0.8447 - val_loss: 7.4877 - val_accuracy: 0.4124\n",
      "Epoch 190/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3939 - accuracy: 0.8472 - val_loss: 7.7283 - val_accuracy: 0.4159\n",
      "Epoch 191/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.4014 - accuracy: 0.8454 - val_loss: 7.6861 - val_accuracy: 0.4167\n",
      "Epoch 192/200\n",
      "759/759 [==============================] - 52s 69ms/step - loss: 0.3885 - accuracy: 0.8489 - val_loss: 7.8636 - val_accuracy: 0.4158\n",
      "Epoch 193/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3922 - accuracy: 0.8479 - val_loss: 7.8932 - val_accuracy: 0.4178\n",
      "Epoch 194/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3914 - accuracy: 0.8483 - val_loss: 7.7809 - val_accuracy: 0.4162\n",
      "Epoch 195/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3951 - accuracy: 0.8471 - val_loss: 7.7420 - val_accuracy: 0.4150\n",
      "Epoch 196/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3890 - accuracy: 0.8496 - val_loss: 7.6775 - val_accuracy: 0.4157\n",
      "Epoch 197/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3804 - accuracy: 0.8528 - val_loss: 7.7470 - val_accuracy: 0.4162\n",
      "Epoch 198/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3913 - accuracy: 0.8494 - val_loss: 7.9260 - val_accuracy: 0.4163\n",
      "Epoch 199/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3853 - accuracy: 0.8514 - val_loss: 7.8679 - val_accuracy: 0.4150\n",
      "Epoch 200/200\n",
      "759/759 [==============================] - 52s 68ms/step - loss: 0.3934 - accuracy: 0.8489 - val_loss: 7.8925 - val_accuracy: 0.4151\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_filepath = '../datasets/vqa-v1/weights.hdf5'\n",
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_datagen, \n",
    "    epochs = 200,\n",
    "    validation_data = val_datagen,\n",
    "    callbacks = [model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "headed-quantity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_datagen = datagen(test_data_whatanimal, 'train2014', batch_size=32, predict_mode=True)\\ntest_output = model.predict(test_datagen)\\nanswers[np.argmax(test_output)]\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_datagen = datagen(test_data_whatanimal, 'train2014', batch_size=32, predict_mode=True)\n",
    "test_output = model.predict(test_datagen)\n",
    "answers[np.argmax(test_output)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "according-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
