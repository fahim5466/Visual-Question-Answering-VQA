{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/ML/datasets/vqa-v1/'\n",
    "ques_dir = dataset_dir+'questions/'\n",
    "ans_dir = dataset_dir+'answers/'\n",
    "\n",
    "ques_train_jsonpath = ques_dir + 'OpenEnded_mscoco_train2014_questions.json'\n",
    "ques_val_jsonpath = ques_dir + 'OpenEnded_mscoco_val2014_questions.json'\n",
    "\n",
    "ans_train_jsonpath = ans_dir + 'mscoco_train2014_annotations.json'\n",
    "ans_val_jsonpath = ans_dir + 'mscoco_val2014_annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_train = json.load(open(ques_train_jsonpath, 'r'))\n",
    "ques_val = json.load(open(ques_val_jsonpath, 'r'))\n",
    "\n",
    "ans_train = json.load(open(ans_train_jsonpath, 'r'))\n",
    "ans_val = json.load(open(ans_val_jsonpath, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total no. of train questions are\",len(ques_train['questions']))\n",
    "print(\"Total no. of validation questions are\",len(ques_val['questions']))\n",
    "\n",
    "print(\"Total no. of train answers are\",len(ans_train['annotations']))\n",
    "print(\"Total no. of validation answers are\",len(ans_val['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3k = []\n",
    "\n",
    "def process(subtype):\n",
    "    \n",
    "    ans = []\n",
    "    ques = []\n",
    "    \n",
    "    if subtype == \"train\":\n",
    "        ans = ans_train\n",
    "        ques = ques_train\n",
    "    else:\n",
    "        ans = ans_val\n",
    "        ques = ques_val\n",
    "    \n",
    "    data=[]\n",
    "    annotations = ans['annotations']\n",
    "    questions = ques['questions']\n",
    "    imdir='COCO_%s2014_%012d.jpg'\n",
    "    \n",
    "    for i in tqdm(range(len(annotations))):\n",
    "        annotation = annotations[i]\n",
    "        question = questions[i]\n",
    "        \n",
    "        answ = annotation['multiple_choice_answer']\n",
    "        im_path = imdir%(subtype, annotation['image_id'])\n",
    "        ques = question['question']\n",
    "        \n",
    "        data.append({'im_path':im_path,'ques':ques,'answ':answ})\n",
    "    \n",
    "    ans_count = defaultdict(int)\n",
    "    for d in data:\n",
    "        a = d['answ']\n",
    "        ans_count[a]+=1;\n",
    "   \n",
    "    global top3k\n",
    "    print(top3k[:100])\n",
    "    if(subtype=='train'):\n",
    "        ans_count = dict(sorted(ans_count.items(), key=lambda item: item[1], reverse=True))\n",
    "        top3k = [k for k,v in ans_count.items()][:3000]\n",
    "        #print(top3k)\n",
    "        #print(len(top3k))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    #print(df)\n",
    "\n",
    "\n",
    "    filtered_df = df.loc[df['answ'].isin(top3k)]\n",
    "    #print(filtered_df)\n",
    "    print('samples filtered out:', len(df)-len(filtered_df))\n",
    "    \n",
    "    rand_df = filtered_df.sample(frac=1).reset_index(drop=True)\n",
    "    #print(rand_df)\n",
    "    \n",
    "    rand_df.to_csv(dataset_dir+subtype+'_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "process(\"train\")\n",
    "process(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(dataset_dir+'train_data.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv(dataset_dir+'val_data.csv')\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['answ'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
